# -*- coding: utf-8 -*-
"""Project-Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uEVb9JFemfGlGrH1DtW0yit92tfS13Dr
"""

!pip install rouge-score
!pip install gradio

# prompt: prompt: create a interface for abstractive summarization for BART, T5, GPT and PEGASUS models and input must be read and for summarization user select any model so create a buttons for models and act accordingly also calculate meter, rouge-p and rouge-1 scores effectively

import torch
from transformers import BartTokenizer, BartForConditionalGeneration, T5Tokenizer,pipeline, T5ForConditionalGeneration, GPT2Tokenizer, GPT2LMHeadModel
import matplotlib.pyplot as plt
import nltk
from nltk.translate.meteor_score import single_meteor_score as meteor_score
import gradio as gr

# Install necessary libraries
!pip install transformers rouge-score nltk gradio

# Download necessary NLTK data
nltk.download('punkt')
nltk.download('wordnet')

# Define the device
dev = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Function to perform summarization based on the selected model
def summarize(text, model_choice):
    try:
        if model_choice == "BART":
            model_name = "facebook/bart-large-cnn"
            tokenizer = BartTokenizer.from_pretrained(model_name)
            model = BartForConditionalGeneration.from_pretrained(model_name).to(dev)
            inputs = tokenizer(text, return_tensors="pt", truncation=True).to(dev)
            summary_ids = model.generate(inputs["input_ids"], do_sample=True,
                                         early_stopping=True, no_repeat_ngram_size=2, length_penalty=2.0, num_beams=4,
                                         min_length=50, max_length=1024)
            summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)
        elif model_choice == "T5":
            summarizer = pipeline("summarization", model="t5-base", device=0 if torch.cuda.is_available() else -1)
            summary = summarizer(text, max_length=130, min_length=30, do_sample=False)[0]["summary_text"]
        elif model_choice == "PEGASUS":
            summarizer = pipeline("summarization", model="google/pegasus-xsum", device=0 if torch.cuda.is_available() else -1)
            summary = summarizer(text, max_length=130, min_length=30, do_sample=False)[0]["summary_text"]
        elif model_choice == "GPT":
            model_name = "gpt2"
            model = GPT2LMHeadModel.from_pretrained(model_name).to(dev)
            tokenizer = GPT2Tokenizer.from_pretrained(model_name)
            inputs = tokenizer(text, return_tensors="pt", truncation=True,max_length=120)
            summary_ids = model.generate(inputs["input_ids"],do_sample=True,
                attention_mask=inputs["attention_mask"],early_stopping=True,no_repeat_ngram_size=2,length_penalty=2.0,num_beams=4, min_length=30, max_length=200)
            summary = tokenizer.decode(summary_ids[0],  skip_special_tokens=True,clean_up_tokenization_spaces=True)
            tokenizer.pad_token = tokenizer.eos_token
        else:
            summary = "Model not implemented yet."
    except Exception as e:
        summary = f"An error occurred: {e}"
    return summary


# Create the Gradio interface
iface = gr.Interface(
    fn=summarize,
    inputs=[
        gr.Textbox(lines=10, label="Input Text"),
        gr.Radio(["BART", "T5", "PEGASUS", "GPT"], label="Choose a summarization model", value="BART"),
    ],
    outputs=gr.Textbox(label="Summary"),
    title="Abstractive Text Summarization",
    description="Select a model and input your text to generate a summary.",
)

# Launch the interface
iface.launch()

# prompt: code for displaying meteor score in pie chart for BART,T5,GPT and PEGASUS

import matplotlib.pyplot as plt

# Sample meteor scores
meteor_scores = {
    'BART': 0.939,
    'T5': 0.127,
    'GPT': 0.498,
    'PEGASUS': 0.064
}

# Extract model names and scores
labels = list(meteor_scores.keys())
sizes = list(meteor_scores.values())

# Create the pie chart
plt.figure(figsize=(8, 8))
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
plt.title('Meteor Scores for Different Summarization Models')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

# prompt: code for displaying rouge-p score in pie chart for BART,T5,GPT and PEGASUS

import matplotlib.pyplot as plt

# Sample ROUGE-P scores (replace with your actual scores)
rouge_p_scores = {
    'BART': 0.945,
    'T5': 0.287,
    'PEGASUS': 0.166,
    'GPT': 0.498
}

# Extract model names and scores
labels = list(rouge_p_scores.keys())
sizes = list(rouge_p_scores.values())

# Create the pie chart
plt.figure(figsize=(8, 8))
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
plt.title('ROUGE-P Scores for Different Summarization Models')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

# prompt: code for displaying rouge-1 score in pie chart for BART,T5,GPT and PEGASUS

import matplotlib.pyplot as plt

# Sample ROUGE-1 scores (replace with your actual scores)
rouge_1_scores = {
    'BART': 0.989,
    'T5': 0.314,
    'GPT': 0.656,
    'PEGASUS': 0.183
}

# Extract model names and scores
labels = list(rouge_1_scores.keys())
sizes = list(rouge_1_scores.values())

# Create the pie chart
plt.figure(figsize=(8, 8))
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
plt.title('ROUGE-1 Scores for Different Summarization Models')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

print(10)